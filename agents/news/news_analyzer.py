import urllib.request
import urllib.parse
import json
import ssl
import time
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from difflib import SequenceMatcher
from deep_translator import GoogleTranslator
from bs4 import BeautifulSoup
import pandas as pd
from typing import List, Dict
from datetime import datetime

client_id = "jWYb81zpxwjjBOvjTlc1"
client_secret = "CH69vSJ6hu"

class MarketImpactAnalyzer:
    def __init__(self):
        self.sector_keywords = {
            'ë°˜ë„ì²´': ['ë°˜ë„ì²´', 'íŒŒìš´ë“œë¦¬', 'DDR', 'DRAM', 'NAND', 'ì›¨ì´í¼'],
            '2ì°¨ì „ì§€': ['2ì°¨ì „ì§€', 'ë°°í„°ë¦¬', 'LFP', 'NCM', 'ì–‘ê·¹ì¬', 'ìŒê·¹ì¬', 'ë¶„ë¦¬ë§‰'],
            'ìë™ì°¨': ['ìë™ì°¨', 'ì „ê¸°ì°¨', 'EV', 'ë‚´ì—°ê¸°ê´€', 'í•˜ì´ë¸Œë¦¬ë“œ'],
            'IT': ['ì†Œí”„íŠ¸ì›¨ì–´', 'í”Œë«í¼', 'í´ë¼ìš°ë“œ', 'AI', 'ì¸ê³µì§€ëŠ¥'],
            'ë°”ì´ì˜¤': ['ì œì•½', 'ë°”ì´ì˜¤', 'ì‹ ì•½', 'ì„ìƒ', 'ë°±ì‹ '],
            'ê¸ˆìœµ': ['ì€í–‰', 'ì¦ê¶Œ', 'ë³´í—˜', 'ì¹´ë“œ', 'í•€í…Œí¬']
        }
        
        self.market_indicators = {
            'ê¸ˆë¦¬': ['ê¸°ì¤€ê¸ˆë¦¬', 'êµ­ê³ ì±„', 'íšŒì‚¬ì±„', 'ê¸ˆë¦¬ì¸ìƒ', 'ê¸ˆë¦¬ì¸í•˜'],
            'í™˜ìœ¨': ['ì›ë‹¬ëŸ¬', 'ì›í™”ê°€ì¹˜', 'í™˜ìœ¨', 'ë‹¬ëŸ¬ì¸ë±ìŠ¤'],
            'ì›ìì¬': ['ìœ ê°€', 'êµ¬ë¦¬', 'ë¦¬íŠ¬', 'ë‹ˆì¼ˆ', 'ì½”ë°œíŠ¸'],
            'ê²½ì œì§€í‘œ': ['GDP', 'ë¬¼ê°€', 'ê³ ìš©', 'ìˆ˜ì¶œ', 'ë¬´ì—­ìˆ˜ì§€']
        }

    def analyze_market_impact(self, news_text: str, stock_name: str) -> Dict:
        """ì‹œì¥ ì˜í–¥ ë¶„ì„"""
        impact_analysis = {
            'impact_level': 0.0,  # -1.0 ~ 1.0
            'confidence_score': 0.0,  # 0.0 ~ 1.0
            'affected_sectors': [],
            'market_indicators': [],
            'related_stocks': [],
            'time_horizon': 'short_term'  # short_term, mid_term, long_term
        }

        # ì„¹í„° ì˜í–¥ ë¶„ì„
        for sector, keywords in self.sector_keywords.items():
            for keyword in keywords:
                if keyword in news_text:
                    if sector not in impact_analysis['affected_sectors']:
                        impact_analysis['affected_sectors'].append(sector)

        # ì‹œì¥ ì§€í‘œ ì˜í–¥ ë¶„ì„
        for indicator, keywords in self.market_indicators.items():
            for keyword in keywords:
                if keyword in news_text:
                    if indicator not in impact_analysis['market_indicators']:
                        impact_analysis['market_indicators'].append(indicator)

        # ì˜í–¥ë„ ê³„ì‚°
        impact_analysis['impact_level'] = self._calculate_impact_level(news_text)
        impact_analysis['confidence_score'] = self._calculate_confidence_score(news_text)
        impact_analysis['time_horizon'] = self._determine_time_horizon(news_text)
        impact_analysis['related_stocks'] = self._find_related_stocks(news_text, stock_name)

        return impact_analysis

    def _calculate_impact_level(self, text: str) -> float:
        """ë‰´ìŠ¤ì˜ ì‹œì¥ ì˜í–¥ë„ ê³„ì‚°"""
        impact_keywords = {
            'positive': ['ê¸‰ë“±', 'ìƒìŠ¹', 'í˜¸ì‹¤ì ', 'ìˆ˜ì£¼', 'í‘ìì „í™˜', 'ë§¤ì¶œì¦ê°€'],
            'negative': ['ê¸‰ë½', 'í•˜ë½', 'ì ìì „í™˜', 'ë§¤ì¶œê°ì†Œ', 'ë¦¬ìŠ¤í¬', 'ìš°ë ¤']
        }
        
        score = 0.0
        for keyword in impact_keywords['positive']:
            if keyword in text:
                score += 0.2
        for keyword in impact_keywords['negative']:
            if keyword in text:
                score -= 0.2
                
        return max(min(score, 1.0), -1.0)

    def _calculate_confidence_score(self, text: str) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        confidence_keywords = ['ì „ë§', 'ì˜ˆìƒ', 'ì¶”ì •', 'í™•ì¸', 'ë°œí‘œ', 'ê³µì‹œ']
        score = 0.0
        
        for keyword in confidence_keywords:
            if keyword in text:
                score += 0.2
                
        return min(score, 1.0)

    def _determine_time_horizon(self, text: str) -> str:
        """ì˜í–¥ ì‹œê°„ ë²”ìœ„ ê²°ì •"""
        short_term = ['ë‹¹ì¼', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì´ë²ˆì£¼', 'ë‹¨ê¸°']
        mid_term = ['ì´ë²ˆë‹¬', 'ë‹¤ìŒë‹¬', 'ë¶„ê¸°', 'ì¤‘ê¸°']
        long_term = ['ë‚´ë…„', 'ì¥ê¸°', 'ì¤‘ì¥ê¸°', 'ë¯¸ë˜']
        
        for term in long_term:
            if term in text:
                return 'long_term'
        for term in mid_term:
            if term in text:
                return 'mid_term'
        return 'short_term'

    def _find_related_stocks(self, text: str, main_stock: str) -> List[str]:
        """ì—°ê´€ ì¢…ëª© ì°¾ê¸°"""
        related = [main_stock]
        return related

class NewsAnalyzer:
    def __init__(self):
        self.market_impact_analyzer = MarketImpactAnalyzer()

    def get_top100_by_volume(self):
        url = "https://finance.naver.com/sise/sise_quant.naver"
        headers = {'User-Agent': 'Mozilla/5.0'}
        req = urllib.request.Request(url, headers=headers)
        context = ssl._create_unverified_context()
        res = urllib.request.urlopen(req, context=context)
        soup = BeautifulSoup(res, "html.parser")

        stock_names = []
        for item in soup.select("table.type_2 tr"):
            td = item.select("td")
            if len(td) > 1:
                name = td[1].get_text(strip=True)
                if name:
                    stock_names.append(name)
            if len(stock_names) >= 10:
                break
        return stock_names

    def is_similar(self, new_text, existing_texts, threshold=0.8):
        for text in existing_texts:
            similarity = SequenceMatcher(None, new_text, text).ratio()
            if similarity > threshold:
                return True
        return False

    def analyze_sentiment_for_stock(self, stock_name):
        encText = urllib.parse.quote(stock_name)
        displayNum = 20
        url = f"https://openapi.naver.com/v1/search/news?query={encText}&display={displayNum}&sort=sim"

        context = ssl._create_unverified_context()
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", client_id)
        request.add_header("X-Naver-Client-Secret", client_secret)

        try:
            response = urllib.request.urlopen(request, context=context)
        except:
            print(f"[ìš”ì²­ ì‹¤íŒ¨] {stock_name}")
            return None

        rescode = response.getcode()
        if rescode != 200:
            return None

        response_body = response.read().decode('utf-8')
        news_data = json.loads(response_body)

        analyzer = SentimentIntensityAnalyzer()
        sentiment_scores = []
        unique_descriptions = []
        latest_title = ""
        market_impacts = []

        for item in news_data['items']:
            title = item['title'].replace('<b>', '').replace('</b>', '')
            description = item['description'].replace('<b>', '').replace('</b>', '')

            if self.is_similar(description, unique_descriptions):
                continue
            unique_descriptions.append(description)
            latest_title = title

            text_kr = f"{title}. {description}"
            
            # ì‹œì¥ ì˜í–¥ ë¶„ì„
            market_impact = self.market_impact_analyzer.analyze_market_impact(text_kr, stock_name)
            market_impacts.append(market_impact)

            try:
                translated = GoogleTranslator(source='ko', target='en').translate(text_kr)
            except Exception as e:
                print(f"[ë²ˆì—­ ì‹¤íŒ¨] {e}")
                continue

            sentiment = analyzer.polarity_scores(translated)
            compound_score = sentiment['compound']
            sentiment_scores.append(compound_score)

        if sentiment_scores:
            avg_score = sum(sentiment_scores) / len(sentiment_scores)
            buy_probability = int(((avg_score + 1) / 2) * 100)
            
            # ì‹œì¥ ì˜í–¥ ì¢…í•©
            avg_impact_level = sum(impact['impact_level'] for impact in market_impacts) / len(market_impacts)
            affected_sectors = list(set([sector for impact in market_impacts for sector in impact['affected_sectors']]))
            
            return {
                "ì¢…ëª©ëª…": stock_name,
                "ê°ì„±ì ìˆ˜": round(avg_score, 3),
                "ë§¤ìˆ˜í™•ë¥ ": buy_probability,
                "ë‰´ìŠ¤ê°¯ìˆ˜": len(sentiment_scores),
                "ìµœì‹ ê¸°ì‚¬ì œëª©": latest_title,
                "ì¶”ì²œ": "ë§¤ìˆ˜ ì¶”ì²œ" if avg_score > 0 else "ë§¤ë„ ì¶”ì²œ" if avg_score < 0 else "ì¤‘ë¦½",
                "ì‹œì¥ì˜í–¥ë„": round(avg_impact_level, 3),
                "ì˜í–¥ì„¹í„°": affected_sectors
            }
        else:
            return {
                "ì¢…ëª©ëª…": stock_name,
                "ê°ì„±ì ìˆ˜": None,
                "ë§¤ìˆ˜í™•ë¥ ": None,
                "ë‰´ìŠ¤ê°¯ìˆ˜": 0,
                "ìµœì‹ ê¸°ì‚¬ì œëª©": "",
                "ì¶”ì²œ": "ë¶„ì„ë¶ˆê°€",
                "ì‹œì¥ì˜í–¥ë„": 0.0,
                "ì˜í–¥ì„¹í„°": []
            }

    def run_sentiment_analysis(self):
        top_stocks = self.get_top100_by_volume()
        print("ğŸ“Š ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ\n")

        results = []
        for stock in top_stocks:
            print(f"ğŸ” {stock} ë¶„ì„ ì¤‘...")
            result = self.analyze_sentiment_for_stock(stock)
            if result:
                results.append(result)
            time.sleep(1.5)

        df = pd.DataFrame(results)
        df.to_csv("sentiment_result.csv", index=False, encoding='utf-8-sig')
        
        with open("sentiment_result.json", "w", encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        return df, results

if __name__ == "__main__":
    analyzer = NewsAnalyzer()
    df_result, json_result = analyzer.run_sentiment_analysis()